(()=>{const e=["nomic-embed-text","mxbai-embed-large","bge-m3","bge-large","snowflake-arctic-embed","all-minilm","paraphrase-multilingual"];let t=null,n=!1,o=!1;function a(e){const t=document.getElementById("extract-all-btn"),n=document.getElementById("stop-extract-btn");e?(t.style.display="none",n.style.display="block"):(t.style.display="block",n.style.display="none")}async function r(){try{const e=await async function(){return await window.electronAPI.getServerPort()}();if(!e)throw new Error("Server port not available");const t=await fetch(`http://localhost:${e}/models`);if(!t.ok)throw new Error(`HTTP error! status: ${t.status}`);return(await t.json()).models||[]}catch(e){return console.error("[ERROR] Failed to load chat models:",e),[]}}async function s(){const e=document.getElementById("document-list");try{const t=await window.electronAPI.getStoredSources();if(function(e){const t=e.length,n=e.filter((e=>100===window.electronAPI.getGraphRAGProgress(e.source).percentage)).length;document.getElementById("stat-total-docs").textContent=t,document.getElementById("stat-extracted-docs").textContent=n}(t),0===t.length)return void(e.innerHTML='\n        <div class="empty-state">\n          <div class="empty-state-icon">üì≠</div>\n          <p>No documents uploaded yet</p>\n          <p style="font-size: 12px; margin-top: 5px;">Click "Upload Documents" to get started</p>\n        </div>\n      ');e.innerHTML="";for(const n of t){const t=n.source.split("/").pop(),o=window.electronAPI.getGraphRAGProgress(n.source),a=document.createElement("div");a.className="document-item",a.dataset.source=n.source;const r=100===o.percentage,s=o.percentage>0&&o.percentage<100;a.innerHTML=`\n        <div class="document-header">\n          <div>\n            <div class="document-name">${t}</div>\n            <div class="document-meta">\n              Model: ${n.models.join(", ")}\n              ${o.totalChunks>0?`‚Ä¢ Chunks: ${o.totalChunks}`:""}\n            </div>\n          </div>\n        </div>\n        <div class="document-actions">\n          <button class="btn btn-small btn-extract" data-source="${n.source}" ${r?"disabled":""}>\n            ${r?"‚úì GraphRAG Extracted":s?"‚ü≥ Continue Extraction":"üï∏Ô∏è Extract GraphRAG"}\n          </button>\n          <button class="btn btn-small btn-delete" data-source="${n.source}">\n            üóëÔ∏è Delete\n          </button>\n        </div>\n        <div class="progress-container" id="progress-${n.source.replace(/[^a-zA-Z0-9]/g,"_")}">\n          <div class="progress-bar-container">\n            <div class="progress-bar" style="width: ${o.percentage}%">\n              ${o.percentage}%\n            </div>\n          </div>\n          <div class="progress-text">\n            Processed: ${o.processedChunks} / ${o.totalChunks} chunks\n          </div>\n        </div>\n      `,e.appendChild(a)}document.querySelectorAll(".btn-extract").forEach((e=>{e.addEventListener("click",(async e=>{const t=e.target.dataset.source;await c(t)}))})),document.querySelectorAll(".btn-delete").forEach((e=>{e.addEventListener("click",(async e=>{const t=e.target.dataset.source,n=t.split("/").pop();if(confirm(`Are you sure you want to delete "${n}"?\n\nThis will remove the document and all associated GraphRAG data.`))try{await window.electronAPI.deleteDocumentFromStore(t),await s()}catch(e){alert(`Failed to delete document: ${e.message}`)}}))}))}catch(t){console.error("[ERROR] Failed to refresh document list:",t),e.innerHTML=`\n      <div class="empty-state">\n        <div class="empty-state-icon">‚ö†Ô∏è</div>\n        <p>Failed to load documents</p>\n        <p style="font-size: 12px; margin-top: 5px;">${t.message}</p>\n      </div>\n    `}}async function c(e){const c=e.split("/").pop(),l=e.replace(/[^a-zA-Z0-9]/g,"_"),d=document.getElementById(`progress-${l}`),i=document.querySelector(`.btn-extract[data-source="${e}"]`);try{if(o)throw new Error("Extraction stopped by user");n=!0,a(!0);let l=t;if(!l){const e=await r();if(0===e.length)throw new Error("No chat models available. Please install a chat model in Ollama.");l=e[0],t=l}console.log(`[GraphRAG] Starting extraction for: ${c} using model: ${l}`),d&&d.classList.add("active"),i&&(i.disabled=!0,i.textContent="‚è≥ Extracting...");const m=e=>{if(o)throw new Error("Extraction stopped by user");if(d){const t=d.querySelector(".progress-bar"),n=d.querySelector(".progress-text"),o=Math.round(e.processed/e.total*100);t&&(t.style.width=`${o}%`,t.textContent=`${o}%`),n&&(n.textContent=`Processed: ${e.processed} / ${e.total} chunks (${e.successful} successful, ${e.skipped} skipped)`)}},u=await window.electronAPI.extractGraphRAGForDocument(e,l,m);if(o)throw new Error("Extraction stopped by user");console.log("[GraphRAG] Extraction complete:",u),i&&(i.textContent="‚úì GraphRAG Extracted",i.disabled=!0),n=!1,o=!1,a(!1),await s(),alert(`‚úì GraphRAG Extraction Complete\n\nDocument: ${c}\nChunks processed: ${u.totalChunks}\nEntities found: ${u.entities}\nRelationships found: ${u.relationships}\nMentions found: ${u.mentions}`)}catch(e){console.error("[ERROR] GraphRAG extraction failed:",e),i&&(i.disabled=!1,i.textContent="üï∏Ô∏è Extract GraphRAG"),n=!1,o=!1,a(!1),d&&d.classList.remove("active"),o||alert(`‚ö†Ô∏è GraphRAG Extraction Failed\n\nError: ${e.message}\n\nPlease check:\n‚Ä¢ Ollama is running\n‚Ä¢ A chat model is available\n‚Ä¢ The document exists in the database`)}}window.addEventListener("DOMContentLoaded",(async()=>{console.log("[DEBUG] Manage RAG window loaded");try{await window.electronAPI.loadVectorStore()}catch(e){console.error("[ERROR] Failed to load vector store:",e)}const l=window.electronAPI.getCurrentEmbedderModel();document.getElementById("current-embed-model").textContent=l;const d=await r(),i=document.getElementById("graph-model-select");d.length>0?(i.innerHTML="",d.forEach((e=>{const t=document.createElement("option");t.value=e,t.textContent=e,i.appendChild(t)})),t=d[0],i.value=t):i.innerHTML='<option value="">No models available</option>',i.addEventListener("change",(e=>{t=e.target.value,console.log("[DEBUG] Selected chat model:",t)})),await s(),document.getElementById("upload-btn").addEventListener("click",(async()=>{try{const t=await window.electronAPI.openFileDialog();if(!t||0===t.length)return void console.log("[DEBUG] No files selected");console.log("[DEBUG] Selected files:",t);const n=t.map((e=>({path:e,name:e.split("/").pop()})));await async function(t){const n=document.getElementById("loading-indicator");try{n.classList.remove("hidden");const a=window.electronAPI.getCurrentEmbedderModel();if(console.log("[DEBUG] Current embedding model:",a),!(await window.electronAPI.checkEmbedModelExists()).exists)throw new Error(`Embedding model "${a}" not found in Ollama.\n\nPlease install it using:\nollama pull ${a}`);if(o=a,!e.some((e=>o.toLowerCase().includes(e.toLowerCase())))&&!confirm(`‚ö†Ô∏è Non-Standard Embedding Model Detected\n\nYou are using: ${a}\n\nThis model is not a standard embedding model. Using a regular LLM may result in lower quality vector representations.\n\nRecommended embedding models:\n${e.map((e=>`‚Ä¢ ${e}`)).join("\n")}\n\nDo you want to continue with "${a}" anyway?`))return void n.classList.add("hidden");for(let e=0;e<t.length;e++){const n=t[e];console.log(`[DEBUG] Processing file ${e+1}/${t.length}:`,n.path);const o=await window.electronAPI.readAndSplit(n.path);console.log(`[DEBUG] Generated ${o.length} chunks for file:`,n.path),await window.electronAPI.saveChunksToFaiss(o),console.log("[DEBUG] Saved chunks to FAISS for file:",n.path)}await s(),n.classList.add("hidden"),alert(`‚úì Successfully uploaded ${t.length} document(s)\n\nYou can now extract GraphRAG entities for each document.`)}catch(e){console.error("[ERROR] Failed to upload documents:",e),n.classList.add("hidden");const t=e.message||"Unknown error";t.includes("Internal Server Error")||t.includes("Ollama")||t.includes("500")?alert(`‚ö†Ô∏è Embedding Failed - Ollama Error\n\n${t}\n\nCommon causes:\n‚Ä¢ The selected model is not an embedding model\n‚Ä¢ The model is not properly installed in Ollama\n‚Ä¢ Ollama service is not responding correctly\n\nRecommended embedding models:\n‚Ä¢ mxbai-embed-large\n‚Ä¢ bge-m3\n‚Ä¢ nomic-embed-text\n\nPlease select a different embedding model and try again.`):alert(`‚ö†Ô∏è Failed to Process Document\n\nError: ${t}\n\nPlease check the file format and try again.`)}var o}(n)}catch(e){console.error("[ERROR] Failed to open file dialog:",e),alert(`Failed to open file dialog: ${e.message}`)}})),document.getElementById("extract-all-btn").addEventListener("click",(async()=>{await async function(){try{const e=(await window.electronAPI.getStoredSources()).filter((e=>window.electronAPI.getGraphRAGProgress(e.source).percentage<100));if(0===e.length)return void alert("All documents are already fully extracted!");if(!t)return void alert("Please select a chat model for GraphRAG extraction first.");if(!confirm(`Extract GraphRAG data from ${e.length} unprocessed document(s)?\n\nChat Model: ${t}\n\nThis may take some time depending on document size.`))return;n=!0,o=!1,a(!0);let r=0;for(let t=0;t<e.length;t++){if(o){console.log("[Batch] Extraction stopped by user");break}const n=e[t];console.log(`[Batch] Processing document ${t+1}/${e.length}: ${n.source}`);try{await c(n.source),r++}catch(e){if(console.error(`[Batch] Failed to extract ${n.source}:`,e),o)break;if(!confirm(`Failed to extract "${n.source.split("/").pop()}":\n\n${e.message}\n\nContinue with remaining documents?`))break}}n=!1,o=!1,a(!1);const l=o?`Extraction stopped!\n\nProcessed ${r} of ${e.length} document(s).\n\nYou can resume extraction at any time.`:`Batch extraction complete!\n\nProcessed ${r} document(s).`;alert(l),await s()}catch(e){console.error("[ERROR] Batch extraction failed:",e),n=!1,o=!1,a(!1),alert(`Batch extraction failed: ${e.message}`)}}()})),document.getElementById("stop-extract-btn").addEventListener("click",(()=>{!async function(){n&&(o=!0,n=!1,a(!1),console.log("[DEBUG] Stop extraction requested"),await s(),alert("Stopping extraction after current document...\n\nProgress has been saved and you can resume later."))}()}))}))})();