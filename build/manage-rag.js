(()=>{const e=["nomic-embed-text","mxbai-embed-large","bge-m3","bge-large","snowflake-arctic-embed","all-minilm","paraphrase-multilingual"];let t=null,n=!1,o=!1,a=null;function r(e){const t=document.getElementById("extract-all-btn"),n=document.getElementById("stop-extract-btn");e?(t.style.display="none",n.style.display="block"):(t.style.display="block",n.style.display="none")}async function s(){try{const e=await async function(){return await window.electronAPI.getServerPort()}();if(!e)throw new Error("Server port not available");const t=await fetch(`http://localhost:${e}/models`);if(!t.ok)throw new Error(`HTTP error! status: ${t.status}`);return(await t.json()).models||[]}catch(e){return console.error("[ERROR] Failed to load chat models:",e),[]}}async function l(){const e=document.getElementById("document-list");try{const t=await window.electronAPI.getStoredSources();if(function(e){const t=e.length,n=e.filter((e=>100===window.electronAPI.getGraphRAGProgress(e.source).percentage)).length;document.getElementById("stat-total-docs").textContent=t,document.getElementById("stat-extracted-docs").textContent=n}(t),0===t.length)return void(e.innerHTML='\n        <div class="empty-state">\n          <div class="empty-state-icon">üì≠</div>\n          <p>No documents uploaded yet</p>\n          <p style="font-size: 12px; margin-top: 5px;">Click "Upload Documents" to get started</p>\n        </div>\n      ');e.innerHTML="";for(const o of t){const t=o.source.split("/").pop(),r=window.electronAPI.getGraphRAGProgress(o.source),s=document.createElement("div");s.className="document-item",s.dataset.source=o.source;const l=100===r.percentage,c=r.percentage>0&&r.percentage<100,d=a===o.source;let i,u=l||n;i=l?"‚úì GraphRAG Extracted":d?"‚è≥ Extracting...":!n||l||d?c?"‚ü≥ Continue Extraction":"üï∏Ô∏è Extract GraphRAG":"‚è∏ Waiting...",s.innerHTML=`\n        <div class="document-header">\n          <div>\n            <div class="document-name" title="${t}">${t}</div>\n            <div class="document-meta">\n              Model: ${o.models.join(", ")}\n              ${r.totalChunks>0?`‚Ä¢ Chunks: ${r.totalChunks}`:""}\n            </div>\n          </div>\n        </div>\n        <div class="document-actions">\n          <button class="btn btn-small btn-extract" data-source="${o.source}" ${u?"disabled":""}>\n            ${i}\n          </button>\n          <button class="btn btn-small btn-delete" data-source="${o.source}">\n            üóëÔ∏è Delete\n          </button>\n        </div>\n        <div class="progress-container" id="progress-${o.source.replace(/[^a-zA-Z0-9]/g,"_")}">\n          <div class="progress-bar-container">\n            <div class="progress-bar" style="width: ${r.percentage}%">\n              ${r.percentage}%\n            </div>\n          </div>\n          <div class="progress-text">\n            Processed: ${r.processedChunks} / ${r.totalChunks} chunks\n          </div>\n        </div>\n      `,e.appendChild(s);const m=s.querySelector(".document-name");m&&requestAnimationFrame((()=>{m.scrollWidth>m.clientWidth&&m.classList.add("fade-out")}))}document.querySelectorAll(".btn-extract").forEach((e=>{e.addEventListener("click",(async e=>{const t=e.target.dataset.source;await c(t)}))})),document.querySelectorAll(".btn-delete").forEach((e=>{e.addEventListener("click",(async e=>{const t=e.target.dataset.source,n=t.split("/").pop();if(confirm(`Are you sure you want to delete "${n}"?\n\nThis will remove the document and all associated GraphRAG data.`))try{await window.electronAPI.deleteDocumentFromStore(t),await l()}catch(e){alert(`Failed to delete document: ${e.message}`)}}))}))}catch(t){console.error("[ERROR] Failed to refresh document list:",t),e.innerHTML=`\n      <div class="empty-state">\n        <div class="empty-state-icon">‚ö†Ô∏è</div>\n        <p>Failed to load documents</p>\n        <p style="font-size: 12px; margin-top: 5px;">${t.message}</p>\n      </div>\n    `}}async function c(e,c=!1){const d=e.split("/").pop(),i=e.replace(/[^a-zA-Z0-9]/g,"_"),u=document.getElementById(`progress-${i}`),m=document.querySelector(`.btn-extract[data-source="${e}"]`);try{if(o){if(c)return void console.log("[GraphRAG] Extraction stopped by user for:",d);console.log("[GraphRAG] Resetting stop flag for individual extraction"),o=!1}a=e,c||(n=!0,r(!0)),await l();let i=t;if(!i){const e=await s();if(0===e.length)throw new Error("No chat models available. Please install a chat model in Ollama.");i=e[0],t=i}console.log(`[GraphRAG] Starting extraction for: ${d} using model: ${i}`),u&&u.classList.add("active"),m&&(m.disabled=!0,m.textContent="‚è≥ Extracting...");const g=e=>{if(o)console.log("[GraphRAG] Progress stopped by user");else if(u){const t=u.querySelector(".progress-bar"),n=u.querySelector(".progress-text"),o=Math.round(e.processed/e.total*100);t&&(t.style.width=`${o}%`,t.textContent=`${o}%`),n&&(n.textContent=`Processed: ${e.processed} / ${e.total} chunks (${e.successful} successful, ${e.skipped} skipped)`)}},p=await window.electronAPI.extractGraphRAGForDocument(e,i,g);console.log("[GraphRAG] Extraction complete:",p),m&&(m.textContent="‚úì GraphRAG Extracted",m.disabled=!0);const h=window.electronAPI.getGraphRAGProgress(e);console.log("[GraphRAG] Extraction result:",p),console.log("[GraphRAG] Actual database progress:",h),a=null,c&&await l(),c||(n=!1,o=!1,r(!1)),c||o||(await l(),alert(`‚úì GraphRAG Extraction Complete\n\nDocument: ${d}\nChunks processed: ${p.totalChunks}\nEntities found: ${p.entities}\nRelationships found: ${p.relationships}\nMentions found: ${p.mentions}`),await l())}catch(e){console.error("[ERROR] GraphRAG extraction failed:",e),a=null;const t=o;m&&(m.disabled=!1,m.textContent="üï∏Ô∏è Extract GraphRAG"),c||(n=!1,o=!1,r(!1)),u&&u.classList.remove("active"),t||alert(`‚ö†Ô∏è GraphRAG Extraction Failed\n\nError: ${e.message}\n\nPlease check:\n‚Ä¢ Ollama is running\n‚Ä¢ A chat model is available\n‚Ä¢ The document exists in the database`)}}window.addEventListener("DOMContentLoaded",(async()=>{console.log("[DEBUG] Manage RAG window loaded");try{await window.electronAPI.loadVectorStore()}catch(e){console.error("[ERROR] Failed to load vector store:",e)}const d=window.electronAPI.getCurrentEmbedderModel();document.getElementById("current-embed-model").textContent=d,window.electronAPI.onEmbedModelChanged((e=>{console.log("[INFO] Embedding model changed to:",e),document.getElementById("current-embed-model").textContent=e}));const i=await s(),u=document.getElementById("graph-model-select");i.length>0?(u.innerHTML="",i.forEach((e=>{const t=document.createElement("option");t.value=e,t.textContent=e,u.appendChild(t)})),t=i[0],u.value=t):u.innerHTML='<option value="">No models available</option>',u.addEventListener("change",(e=>{t=e.target.value,console.log("[DEBUG] Selected chat model:",t)})),await l(),document.getElementById("upload-btn").addEventListener("click",(async()=>{try{const t=await window.electronAPI.openFileDialog();if(!t||0===t.length)return void console.log("[DEBUG] No files selected");console.log("[DEBUG] Selected files:",t);const n=t.map((e=>({path:e,name:e.split("/").pop()})));await async function(t){const n=document.getElementById("loading-indicator");try{n.classList.remove("hidden");const a=window.electronAPI.getCurrentEmbedderModel();if(console.log("[DEBUG] Current embedding model:",a),!(await window.electronAPI.checkEmbedModelExists()).exists)throw new Error(`Embedding model "${a}" not found in Ollama.\n\nPlease install it using:\nollama pull ${a}`);if(o=a,!e.some((e=>o.toLowerCase().includes(e.toLowerCase())))&&!confirm(`‚ö†Ô∏è Non-Standard Embedding Model Detected\n\nYou are using: ${a}\n\nThis model is not a standard embedding model. Using a regular LLM may result in lower quality vector representations.\n\nRecommended embedding models:\n${e.map((e=>`‚Ä¢ ${e}`)).join("\n")}\n\nDo you want to continue with "${a}" anyway?`))return void n.classList.add("hidden");for(let e=0;e<t.length;e++){const n=t[e];console.log(`[DEBUG] Processing file ${e+1}/${t.length}:`,n.path);const o=await window.electronAPI.readAndSplit(n.path);console.log(`[DEBUG] Generated ${o.length} chunks for file:`,n.path),await window.electronAPI.saveChunksToFaiss(o),console.log("[DEBUG] Saved chunks to FAISS for file:",n.path)}await l(),n.classList.add("hidden"),alert(`‚úì Successfully uploaded ${t.length} document(s)\n\nYou can now extract GraphRAG entities for each document.`)}catch(e){console.error("[ERROR] Failed to upload documents:",e),n.classList.add("hidden");const t=e.message||"Unknown error";t.includes("Internal Server Error")||t.includes("Ollama")||t.includes("500")?alert(`‚ö†Ô∏è Embedding Failed - Ollama Error\n\n${t}\n\nCommon causes:\n‚Ä¢ The selected model is not an embedding model\n‚Ä¢ The model is not properly installed in Ollama\n‚Ä¢ Ollama service is not responding correctly\n\nRecommended embedding models:\n‚Ä¢ mxbai-embed-large\n‚Ä¢ bge-m3\n‚Ä¢ nomic-embed-text\n\nPlease select a different embedding model and try again.`):alert(`‚ö†Ô∏è Failed to Process Document\n\nError: ${t}\n\nPlease check the file format and try again.`)}var o}(n)}catch(e){console.error("[ERROR] Failed to open file dialog:",e),alert(`Failed to open file dialog: ${e.message}`)}})),document.getElementById("extract-all-btn").addEventListener("click",(async()=>{await async function(){try{const e=(await window.electronAPI.getStoredSources()).filter((e=>window.electronAPI.getGraphRAGProgress(e.source).percentage<100));if(0===e.length)return void alert("All documents are already fully extracted!");if(!t)return void alert("Please select a chat model for GraphRAG extraction first.");if(!confirm(`Extract GraphRAG data from ${e.length} unprocessed document(s)?\n\nChat Model: ${t}\n\nThis may take some time depending on document size.`))return;n=!0,o=!1,r(!0);let a=0;for(let t=0;t<e.length;t++){if(o){console.log("[Batch] Extraction stopped by user");break}const n=e[t];console.log(`[Batch] Processing document ${t+1}/${e.length}: ${n.source}`);try{await c(n.source,!0),a++}catch(e){if(console.error(`[Batch] Failed to extract ${n.source}:`,e),o)break;if(!confirm(`Failed to extract "${n.source.split("/").pop()}":\n\n${e.message}\n\nContinue with remaining documents?`))break}}const s=o;n=!1,o=!1,r(!1);const d=s?`Extraction stopped!\n\nProcessed ${a} of ${e.length} document(s).\n\nYou can resume extraction at any time.`:`Batch extraction complete!\n\nProcessed ${a} document(s).`;alert(d),await l()}catch(e){console.error("[ERROR] Batch extraction failed:",e),n=!1,o=!1,r(!1),alert(`Batch extraction failed: ${e.message}`)}}()})),document.getElementById("stop-extract-btn").addEventListener("click",(()=>{!async function(){n&&(o=!0,n=!1,a=null,r(!1),console.log("[DEBUG] Stop extraction requested"),await l())}()})),window.addEventListener("beforeunload",(()=>{n&&(console.log("[DEBUG] Window closing during extraction, stopping extraction..."),o=!0,n=!1)}))}))})();